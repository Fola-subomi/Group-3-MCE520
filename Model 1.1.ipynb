{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyOi4UQlVbwlvVzAWE8xu+yb"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["#Import Libraries\n","import cv2\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import tensorflow as tf\n","from tensorflow.keras import layers, models\n","from tensorflow.keras.applications import ResNet50\n","from tensorflow.keras.preprocessing import image\n","from tensorflow.keras.preprocessing.image import load_img, img_to_array\n","import os\n","import shutil\n","import random"],"metadata":{"id":"yNCez2wrT2i1"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Experiment with: Median filter, Histogram Equalization\n","RGB\n","10 Epochs\n","Softmax activation function\n","spatse categorical cross entropy"],"metadata":{"id":"c9dO2-XF-RgA"}},{"cell_type":"code","source":["from google.colab import drive\n","\n","# Mount Google Drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"RisBacC-URHn","executionInfo":{"status":"ok","timestamp":1747282397106,"user_tz":420,"elapsed":39626,"user":{"displayName":"Precious Akogun","userId":"05303770301664757955"}},"outputId":"f759e0d3-11c2-4f61-d556-a16489693de9"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","source":["# Navigate to your folder (replace with your actual folder path)\n","folder_path = '/content/drive/My Drive/split_dataset'\n","\n","# List files in the folder\n","os.listdir(folder_path)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"UnGtl8NQUWP6","executionInfo":{"status":"ok","timestamp":1747282397999,"user_tz":420,"elapsed":901,"user":{"displayName":"Precious Akogun","userId":"05303770301664757955"}},"outputId":"d1a533c6-5db5-45e3-a7e3-9463cd1c46ee"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['images', 'split_dataset', 'labels', '__MACOSX']"]},"metadata":{},"execution_count":3}]},{"cell_type":"code","source":["def load_image_and_label(image_path, label_path, image_size=(224, 224)):\n","    image_path = image_path.numpy().decode('utf-8')\n","    label_path = label_path.numpy().decode('utf-8')\n","\n","    img = cv2.imread(image_path)\n","    image_size_int = (int(image_size[0]), int(image_size[1]))\n","    img = cv2.resize(img, image_size_int)\n","\n","    # Median filter for noise reduction\n","    img = cv2.medianBlur(img, 5)\n","\n","    # Normalize image\n","    img = img.astype(np.float32) / 255.0\n","\n","    # High-pass filter for enhancement on grayscale version\n","    img_gray = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n","    img_gray = cv2.resize(img_gray, image_size_int)\n","    kernel = np.array([[-1, -1, -1],\n","                       [-1,  8, -1],\n","                       [-1, -1, -1]])\n","    high_pass = cv2.filter2D(img_gray, -1, kernel)\n","\n","    # Load label and create one-hot vector\n","    with open(label_path, 'r') as file:\n","        line = file.readline().strip()\n","        class_id = int(line.split()[0]) if line else 0\n","\n","    label_vector = np.zeros(num_classes, dtype=np.float32)\n","    label_vector[class_id] = 1.0\n","\n","    return img, high_pass.astype(np.float32) / 255.0, label_vector"],"metadata":{"id":"lkt_w3FpUcTL"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def tf_load_image_and_label(image_path, label_path, image_size=(224, 224)):\n","    img, img_gray, label = tf.py_function(\n","        func=load_image_and_label,\n","        inp=[image_path, label_path, image_size],\n","        Tout=[tf.float32, tf.float32, tf.int32]\n","    )\n","    img.set_shape((image_size[0], image_size[1], 3))\n","    img_gray.set_shape((image_size[0], image_size[1]))\n","    label.set_shape(())\n","\n","    return img, label"],"metadata":{"id":"LVwPWM5-UmS3"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"r2j_sfQZTP59"},"outputs":[],"source":["import os\n","import tensorflow as tf\n","\n","def create_dataset(image_dir, label_dir, image_size=(224, 224), batch_size=32, dataset_type='train', show_warnings=True):\n","    sub_image_dir = os.path.join(image_dir, dataset_type)\n","    sub_label_dir = os.path.join(label_dir, dataset_type)\n","\n","    # Get a list of image files\n","    image_paths = [f for f in os.listdir(sub_image_dir) if f.endswith(('.jpg', '.png'))]\n","\n","    image_file_paths = []\n","    label_file_paths = []\n","\n","    # Check for corresponding label file for each image\n","    for image_name in image_paths:\n","        base_name = os.path.splitext(image_name)[0]\n","        label_name = base_name + '.txt'\n","        label_path = os.path.join(sub_label_dir, label_name)\n","\n","        if os.path.exists(label_path):\n","            image_file_paths.append(os.path.join(sub_image_dir, image_name))\n","            label_file_paths.append(label_path)\n","        else:\n","            if show_warnings:\n","                print(f\"Warning: Missing label file for image: {image_name}\")\n","\n","    if not image_file_paths:\n","        if show_warnings:\n","            print(f\"Warning: No valid image-label pairs found in {sub_image_dir}\")\n","        return tf.data.Dataset.from_tensor_slices(())\n","\n","    # Create dataset and map preprocessing\n","    dataset = tf.data.Dataset.from_tensor_slices((image_file_paths, label_file_paths))\n","    dataset = dataset.map(\n","        lambda img_path, lbl_path: tf_load_image_and_label(img_path, lbl_path, image_size),\n","        num_parallel_calls=tf.data.AUTOTUNE\n","    )\n","\n","    # Shuffle if training\n","    if dataset_type == 'train':\n","        dataset = dataset.shuffle(buffer_size=len(image_file_paths))\n","\n","    # Batch and prefetch\n","    dataset = dataset.batch(batch_size).prefetch(tf.data.AUTOTUNE)\n","\n","    return dataset\n"]},{"cell_type":"code","source":["# Number of output classes (adjust based on your dataset)\n","num_classes = 2  # <-- change this if you have a different number of classes\n","\n","# Define the CNN model\n","model = models.Sequential([\n","    layers.Input(shape=(224, 224, 3)),\n","\n","    layers.Conv2D(32, (3, 3), activation='relu'),\n","    layers.MaxPooling2D((2, 2)),\n","\n","    layers.Conv2D(64, (3, 3), activation='relu'),\n","    layers.MaxPooling2D((2, 2)),\n","\n","    layers.Conv2D(128, (3, 3), activation='relu'),\n","    layers.MaxPooling2D((2, 2)),\n","\n","    layers.Flatten(),\n","    layers.Dense(128, activation='relu'),\n","    layers.Dropout(0.5),\n","    layers.Dense(num_classes, activation='softmax')\n","])"],"metadata":{"id":"U7BZGqk5UuMR"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Define paths to your main image and label directories\n","image_dir = '/content/drive/My Drive/split_dataset/images'\n","label_dir = '/content/drive/My Drive/split_dataset/labels'\n","\n","# Create the training, validation, and test datasets\n","train_dataset = create_dataset(image_dir, label_dir, image_size=(224, 224), batch_size=32, dataset_type='train')\n","val_dataset = create_dataset(image_dir, label_dir, image_size=(224, 224), batch_size=32, dataset_type='val')\n","test_dataset = create_dataset(image_dir, label_dir, image_size=(224, 224), batch_size=32, dataset_type='test')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"awevbBWmUy2w","executionInfo":{"status":"ok","timestamp":1747282414469,"user_tz":420,"elapsed":16232,"user":{"displayName":"Precious Akogun","userId":"05303770301664757955"}},"outputId":"5169ef35-ecea-43d9-a9f9-6bd6827cc5dd"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Warning: Missing label file for image: image_1614.jpg\n"]}]},{"cell_type":"code","source":["model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n","\n","history = model.fit(train_dataset, epochs=10, validation_data=val_dataset)\n","model.evaluate(test_dataset)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"OfEXh8j7U4vG","outputId":"9adb5900-20fc-4339-b442-e79510a08b52"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/10\n"]}]},{"cell_type":"code","source":["# Access loss and accuracy history\n","train_loss = history.history['loss']  # List of training loss values per epoch\n","train_accuracy = history.history['accuracy']  # List of training accuracy values per epoch\n","val_loss = history.history['val_loss']  # List of validation loss values per epoch\n","val_accuracy = history.history['val_accuracy']  # List of validation accuracy values per epoch\n","\n","# Print the final values of loss and accuracy for the last epoch\n","print(f\"Final Training Loss: {train_loss[-1]}\")\n","print(f\"Final Training Accuracy: {train_accuracy[-1]}\")\n","print(f\"Final Validation Loss: {val_loss[-1]}\")\n","print(f\"Final Validation Accuracy: {val_accuracy[-1]}\")"],"metadata":{"id":"N3MB3jRxVF80"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import matplotlib.pyplot as plt\n","\n","# Plot Training & Validation Loss\n","plt.figure(figsize=(12, 6))\n","plt.subplot(1, 2, 1)\n","plt.plot(train_loss, label='Train Loss')\n","plt.plot(val_loss, label='Validation Loss')\n","plt.title('Loss during Training')\n","plt.xlabel('Epoch')\n","plt.ylabel('Loss')\n","plt.legend()\n","\n","# Plot Training & Validation Accuracy\n","plt.subplot(1, 2, 2)\n","plt.plot(train_accuracy, label='Train Accuracy')\n","plt.plot(val_accuracy, label='Validation Accuracy')\n","plt.title('Accuracy during Training')\n","plt.xlabel('Epoch')\n","plt.ylabel('Accuracy')\n","plt.legend()\n","\n","plt.show()"],"metadata":{"id":"38PVJdpxVK4L"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Evaluate the model on test data\n","test_loss, test_accuracy = model.evaluate(test_dataset)\n","\n","print(f\"Test Loss: {test_loss}\")\n","print(f\"Test Accuracy: {test_accuracy}\")"],"metadata":{"id":"_Q-CkNhnVS2G"},"execution_count":null,"outputs":[]}]}